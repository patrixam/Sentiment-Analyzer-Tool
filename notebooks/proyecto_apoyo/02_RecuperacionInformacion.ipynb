{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrixam/Sentiment-Analyzer-Tool/blob/master/notebooks/proyecto_apoyo/02_RecuperacionInformacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RECUPERADORES DISPERSOS"
      ],
      "metadata": {
        "id": "j6JOsqKjdami"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TF-IDF"
      ],
      "metadata": {
        "id": "A5iedDc4g6Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Base de conocimiento\n",
        "data = [\n",
        "    \"Resetear contraseña\", \"Encontrar número de serie\", \"Dispositivo no enciende\"\n",
        "]\n",
        "vectorizer = TfidfVectorizer()\n",
        "vector_matrix = vectorizer.fit_transform(data)\n",
        "\n",
        "# Consulta del usuario\n",
        "query = \"olvidé mi contraseña\"\n",
        "#query = \"olvidé mi clave\"\n",
        "query_vec = vectorizer.transform([query])\n",
        "similarities = cosine_similarity(query_vec, vector_matrix).flatten()\n",
        "\n",
        "# Mostrar resultados\n",
        "ranking = similarities.argsort()[::-1]\n",
        "for idx in ranking:\n",
        "    print(f\"Documento: {data[idx]} | Similitud: {similarities[idx]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lehNgFoYhXtb",
        "outputId": "2b8c0de2-48ee-4952-e3ff-135c074ce490"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento: Resetear contraseña | Similitud: 0.71\n",
            "Documento: Dispositivo no enciende | Similitud: 0.00\n",
            "Documento: Encontrar número de serie | Similitud: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear DataFrame para mostrar vectores\n",
        "df_docs = pd.DataFrame(vector_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=data)\n",
        "df_query = pd.DataFrame(query_vec.toarray(), columns=vectorizer.get_feature_names_out(), index=[\"Consulta\"])\n",
        "df_total = pd.concat([df_docs, df_query])\n",
        "\n",
        "# Mostrar los vectores\n",
        "print(\"Vectores TF-IDF:\")\n",
        "print(df_total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXqikOdHo2ht",
        "outputId": "18ab0d22-206f-4b06-ffb1-35c24b1630b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectores TF-IDF:\n",
            "                           contraseña   de  dispositivo  enciende  encontrar  \\\n",
            "Resetear contraseña          0.707107  0.0      0.00000   0.00000        0.0   \n",
            "Encontrar número de serie    0.000000  0.5      0.00000   0.00000        0.5   \n",
            "Dispositivo no enciende      0.000000  0.0      0.57735   0.57735        0.0   \n",
            "Consulta                     1.000000  0.0      0.00000   0.00000        0.0   \n",
            "\n",
            "                                no  número  resetear  serie  \n",
            "Resetear contraseña        0.00000     0.0  0.707107    0.0  \n",
            "Encontrar número de serie  0.00000     0.5  0.000000    0.5  \n",
            "Dispositivo no enciende    0.57735     0.0  0.000000    0.0  \n",
            "Consulta                   0.00000     0.0  0.000000    0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RECUPERADORES DENSOS"
      ],
      "metadata": {
        "id": "JgrWLgV2dkJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WORD2VEC"
      ],
      "metadata": {
        "id": "GucIgzq4flnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 scipy==1.13.1 gensim==4.3.3 spacy==3.7.5"
      ],
      "metadata": {
        "id": "DbY3pmBWgEEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Base de conocimiento\n",
        "data = [\"Resetear contraseña\", \"Encontrar número de serie\", \"Dispositivo no enciende\"]\n",
        "sentences = [frase.lower().split() for frase in data]\n",
        "\n",
        "# Entrenar modelo Word2Vec\n",
        "model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=2)\n",
        "\n",
        "# Promediar vectores por frase\n",
        "def sentence_vector(sentence, model):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "data_vectors = [sentence_vector(texto, model) for texto in data]\n",
        "\n",
        "# Consulta\n",
        "query = \"olvidé mi clave\"\n",
        "query_vec = sentence_vector(query, model)\n",
        "\n",
        "# Similaridades\n",
        "similarities = cosine_similarity([query_vec], data_vectors).flatten()\n",
        "\n",
        "# Ranking\n",
        "ranking = similarities.argsort()[::-1]\n",
        "for idx in ranking:\n",
        "    print(f\"Documento: {data[idx]} | Similitud: {similarities[idx]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDzYdSmuffjG",
        "outputId": "5dbb0a3b-117d-4fa0-993f-71b04692fcdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento: Dispositivo no enciende | Similitud: 0.00\n",
            "Documento: Encontrar número de serie | Similitud: 0.00\n",
            "Documento: Resetear contraseña | Similitud: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FastText"
      ],
      "metadata": {
        "id": "7aOpPaUAgtKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Base de conocimiento\n",
        "data = [\n",
        "    \"Resetear contraseña\",\n",
        "    \"Encontrar número de serie\",\n",
        "    \"Dispositivo no enciende\"\n",
        "]\n",
        "\n",
        "# Preprocesamiento: convertir a listas de palabras\n",
        "tokenized_data = [frase.lower().split() for frase in data]\n",
        "\n",
        "# Entrenar modelo FastText desde cero\n",
        "model = FastText(sentences=tokenized_data, vector_size=100, window=3, min_count=1, epochs=50)\n",
        "\n",
        "# Función para vectorizar una frase (media de los vectores de las palabras)\n",
        "def sentence_vector(sentence, model):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "# Vectorizar base de conocimiento\n",
        "data_vectors = [sentence_vector(frase, model) for frase in data]\n",
        "\n",
        "# Consulta\n",
        "query = \"olvidé mi clave\"\n",
        "query_vec = sentence_vector(query, model)\n",
        "\n",
        "# Calcular similitud de coseno\n",
        "similarities = cosine_similarity([query_vec], data_vectors).flatten()\n",
        "\n",
        "# Mostrar ranking\n",
        "ranking = similarities.argsort()[::-1]\n",
        "for idx in ranking:\n",
        "    print(f\"Documento: {data[idx]} | Similitud: {similarities[idx]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a_UmHkzguxU",
        "outputId": "f2c482fb-d556-49e8-b0d0-055993b26480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento: Dispositivo no enciende | Similitud: 0.05\n",
            "Documento: Encontrar número de serie | Similitud: -0.02\n",
            "Documento: Resetear contraseña | Similitud: -0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Cargar modelo FastText preentrenado en español\n",
        "#model = KeyedVectors.load_word2vec_format('cc.es.300.vec.gz', binary=False)\n",
        "\n",
        "# Base de conocimiento\n",
        "data = [\"Resetear contraseña\", \"Encontrar número de serie\", \"Dispositivo no enciende\"]\n",
        "\n",
        "# Promediar vectores de cada frase\n",
        "def sentence_vector(sentence, model):\n",
        "    words = sentence.lower().split()\n",
        "    vectors = [model[word] for word in words if word in model]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "data_vectors = [sentence_vector(texto, model) for texto in data]\n",
        "\n",
        "# Consulta\n",
        "query = \"olvidé mi clave\"\n",
        "query_vec = sentence_vector(query, model)\n",
        "\n",
        "# Similaridades\n",
        "similarities = cosine_similarity([query_vec], data_vectors).flatten()\n",
        "\n",
        "# Ranking\n",
        "ranking = similarities.argsort()[::-1]\n",
        "for idx in ranking:\n",
        "    print(f\"Documento: {data[idx]} | Similitud: {similarities[idx]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lpq9f9ehXyf",
        "outputId": "e1c581dd-6b0f-4d1e-8075-5b78e3efac52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento: Dispositivo no enciende | Similitud: 0.34\n",
            "Documento: Resetear contraseña | Similitud: 0.33\n",
            "Documento: Encontrar número de serie | Similitud: 0.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRANSFORMERS\n"
      ],
      "metadata": {
        "id": "Y68fUxPChMlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelo preentrenado: paraphrase-multilingual-MiniLM-L12-v2\n"
      ],
      "metadata": {
        "id": "LbC5OVKhqF5q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOIH9SjNh4Gb",
        "outputId": "12bd6dac-b131-4205-9568-c2bd272cfd84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento: Resetear contraseña | Similitud: 0.55\n",
            "Documento: Dispositivo no enciende | Similitud: 0.32\n",
            "Documento: Encontrar número de serie | Similitud: 0.11\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Base de conocimiento\n",
        "data = [\n",
        "    \"Resetear contraseña\", \"Encontrar número de serie\", \"Dispositivo no enciende\"\n",
        "]\n",
        "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "data_embeddings = model.encode(data, convert_to_tensor=True)\n",
        "\n",
        "# Consulta del usuario\n",
        "#query = \"olvidé mi contraseña\"\n",
        "query = \"olvidé mi clave\"\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "similarities = util.pytorch_cos_sim(query_embedding, data_embeddings).squeeze()\n",
        "\n",
        "# Mostrar resultados\n",
        "ranking = similarities.argsort(descending=True)\n",
        "for idx in ranking:\n",
        "    print(f\"Documento: {data[idx]} | Similitud: {similarities[idx]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelo distiluse-base-multilingual-cased-v1\n"
      ],
      "metadata": {
        "id": "3c12lvCBh_ud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696cc82f-fa68-4c91-e280-ab4bb05ec926",
        "id": "sNpLDAt8iFjP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento: Resetear contraseña | Similitud: 0.46\n",
            "Documento: Encontrar número de serie | Similitud: 0.19\n",
            "Documento: Dispositivo no enciende | Similitud: 0.15\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Base de conocimiento\n",
        "data = [\n",
        "    \"Resetear contraseña\", \"Encontrar número de serie\", \"Dispositivo no enciende\"\n",
        "]\n",
        "model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
        "data_embeddings = model.encode(data, convert_to_tensor=True)\n",
        "\n",
        "# Consulta del usuario\n",
        "#query = \"olvidé mi contraseña\"\n",
        "query = \"olvidé mi clave\"\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "similarities = util.pytorch_cos_sim(query_embedding, data_embeddings).squeeze()\n",
        "\n",
        "# Mostrar resultados\n",
        "ranking = similarities.argsort(descending=True)\n",
        "for idx in ranking:\n",
        "    print(f\"Documento: {data[idx]} | Similitud: {similarities[idx]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejemplo de comparación temporal"
      ],
      "metadata": {
        "id": "xVDdSmsMsB2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculando embeddings"
      ],
      "metadata": {
        "id": "2Qbqh5INFiaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "7icBh8cHuOKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Cargar un subset del dataset de Wikipedia en español\n",
        "dataset = load_dataset(\"wikimedia/wikipedia\",\"20231101.es\", split=\"train\",trust_remote_code=True)\n",
        "data = [item[\"text\"] for item in dataset.select(range(20000)) if isinstance(item[\"text\"], str)]\n",
        "\n",
        "# Consulta del usuario\n",
        "query = \"¿Cuándo finalizó la Segunda Guerra Mundial?\"\n",
        "\n",
        "# **TF-IDF**\n",
        "vectorizer = TfidfVectorizer()\n",
        "start_time_tfidf = time.time()\n",
        "vector_matrix = vectorizer.fit_transform(data)\n",
        "query_vec = vectorizer.transform([query])\n",
        "tfidf_similarities = cosine_similarity(query_vec, vector_matrix).flatten()\n",
        "end_time_tfidf = time.time()\n",
        "\n",
        "# Ordenar resultados TF-IDF\n",
        "ranking_tfidf = tfidf_similarities.argsort()[::-1]\n",
        "top_tfidf = [(data[idx], tfidf_similarities[idx], dataset['title'][idx]) for idx in ranking_tfidf[:5]]\n",
        "\n",
        "# Embeddings\n",
        "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # Modelo multilingüe para español\n",
        "start_time_embeddings = time.time()\n",
        "data_embeddings = model.encode(data, convert_to_tensor=True)\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "embedding_similarities = util.pytorch_cos_sim(query_embedding, data_embeddings).squeeze().cpu().numpy()\n",
        "end_time_embeddings = time.time()\n",
        "\n",
        "# Ordenar resultados Embeddings\n",
        "ranking_embeddings = embedding_similarities.argsort()[::-1]\n",
        "top_embeddings = [(data[idx], embedding_similarities[idx],dataset['title'][idx]) for idx in ranking_embeddings[:5]]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"=== Resultados TF-IDF ===\")\n",
        "print(f\"Tiempo de cálculo: {end_time_tfidf - start_time_tfidf:.4f} segundos\")\n",
        "for idx, (doc, sim, tit) in enumerate(top_tfidf):\n",
        "    print(f\"\\nDocumento {idx+1}:\")\n",
        "    print(f\"Similitud: {sim:.4f}\\n{tit}\\n{doc[:300]}\")\n",
        "\n",
        "print(\"\\n=== Resultados Embeddings ===\")\n",
        "print(f\"Tiempo de cálculo: {end_time_embeddings - start_time_embeddings:.4f} segundos\")\n",
        "for idx, (doc, sim,tit) in enumerate(top_embeddings):\n",
        "    print(f\"\\nDocumento {idx+1}:\")\n",
        "    print(f\"Similitud: {sim:.4f}\\n{tit}\\n{doc[:300]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k13E-2W4spu5",
        "outputId": "24e36a25-da93-445a-b47d-13c24cdc5909"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Resultados TF-IDF ===\n",
            "Tiempo de cálculo: 36.9988 segundos\n",
            "\n",
            "Documento 1:\n",
            "Similitud: 0.2366\n",
            "Guerra mundial\n",
            "Guerra mundial es un término utilizado para referirse a una batalla que puede durar días, semanas, meses o hasta años y que puede involucrar directamente a varias naciones de distintos continentes.\n",
            "\n",
            "Discrepancias en el término \n",
            "Pese a ser aceptadas las varias guerras mundiales, publicaciones como lo\n",
            "\n",
            "Documento 2:\n",
            "Similitud: 0.2112\n",
            "Guerra\n",
            "La guerra, estrictamente hablando, es aquel conflicto social en el que dos o más grupos humanos relativamente masivos —principalmente tribus, sociedades o naciones— se enfrentan de manera violenta, generalmente mediante el uso de armas de toda índole, a menudo con resultado de muerte —individual o c\n",
            "\n",
            "Documento 3:\n",
            "Similitud: 0.1803\n",
            "Conferencia de París (1945)\n",
            "La conferencia de París de 1945 (9 de noviembre al 21 de diciembre), fue una reunión celebrada por los representantes de los Estados aliados para decidir las reparaciones de guerra a imponer a Alemania tras su derrota en la II Guerra Mundial.\n",
            "\n",
            "Véase también \n",
            " Conferencia de París (1919) - Reunión co\n",
            "\n",
            "Documento 4:\n",
            "Similitud: 0.1586\n",
            "Victoria pírrica\n",
            "Una victoria pírrica es aquella que se consigue con muchas pérdidas en el bando aparentemente o tácticamente vencedor, de modo que incluso tal victoria puede terminar siendo desfavorable para dicho bando.\n",
            "\n",
            "El nombre proviene de Pirro, rey de Epiro, quien logró una victoria sobre los romanos con el c\n",
            "\n",
            "Documento 5:\n",
            "Similitud: 0.1506\n",
            "Guerras del golfo Pérsico\n",
            "Las guerras del golfo Pérsico fueron una serie de conflictos militares armados de los siglos  y , entre países del hemisferio occidental y sus aliados e Irak:\n",
            "\n",
            " La guerra Irán-Irak (1980-1988). Fue una guerra entre Irán e Irak como resultado de la invasión del segundo, bajo el gobierno de Saddam, qu\n",
            "\n",
            "=== Resultados Embeddings ===\n",
            "Tiempo de cálculo: 249.7286 segundos\n",
            "\n",
            "Documento 1:\n",
            "Similitud: 0.7627\n",
            "1945\n",
            "1945 () fue un año común comenzado en lunes según el calendario gregoriano.\n",
            "\n",
            "Este año marcó el fin  de la Segunda Guerra Mundial, tras la derrota de las Potencias del Eje (la Italia Fascista, la Alemania Nazi  y el Japón Imperial respectivamente); las fuerzas aliadas (particularmente Estados Unidos \n",
            "\n",
            "Documento 2:\n",
            "Similitud: 0.7300\n",
            "1918\n",
            "1918 () fue un año común comenzado en martes según el calendario gregoriano. \n",
            "\n",
            "Este año marcó el fin de la Gran Guerra (Primera guerra mundial), conflicto que resultó en la muerte de entre 15 y 22 millones de personas (1 % de la población total en ese momento). Las consecuencias de la guerra continu\n",
            "\n",
            "Documento 3:\n",
            "Similitud: 0.6928\n",
            "Segunda Guerra Mundial\n",
            "La Segunda Guerra Mundial (también escrito II Guerra Mundial) fue un conflicto militar global que se desarrolló entre 1939 y 1945. En ella se vieron implicadas la mayor parte de las naciones del mundo —incluidas todas las grandes potencias, así como prácticamente todas las naciones europeas— agrupad\n",
            "\n",
            "Documento 4:\n",
            "Similitud: 0.6508\n",
            "1943\n",
            "1943 () fue un año común comenzado en viernes del calendario gregoriano.\n",
            "\n",
            "Acontecimientos\n",
            "\n",
            "Enero \n",
            " 1 de enero: en el marco de la Segunda Guerra Mundial, finaliza la larga batalla de Guadalcanal, con la victoria de los estadounidenses sobre los japoneses.\n",
            " 11 de enero: El Reino Unido y Estados Unidos\n",
            "\n",
            "Documento 5:\n",
            "Similitud: 0.6290\n",
            "1914\n",
            "1914 () fue un año común comenzado en jueves según el calendario gregoriano.\n",
            "\n",
            "En este año inició la Primera Guerra Mundial, el segundo conflicto más sangriento y destructivo de la historia humana hasta aquel momento (siendo solo superado por las Guerras Ming-Qing de 1618–1644 en China). La llamada \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cargando embeddings pre-calculados"
      ],
      "metadata": {
        "id": "mMh0K4-AFYcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora guardo los modelos, embeddings y vectores para agilizar el proceso."
      ],
      "metadata": {
        "id": "7e91D60I346z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardo los embeddings y vectores ya generados anteriormente\n",
        "import pickle\n",
        "\n",
        "with open('data_embeddings.pkl', 'wb') as f:\n",
        "    pickle.dump(data_embeddings, f)\n",
        "\n",
        "with open('vector_matrix.pkl', 'wb') as f:\n",
        "    pickle.dump(vector_matrix, f)\n",
        "\n",
        "with open('vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "#guardo el modelo\n",
        "model.save('model')\n"
      ],
      "metadata": {
        "id": "-vloBLag2dPG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardo los datos (data y dataset)\n",
        "import pickle\n",
        "\n",
        "with open('data.pkl', 'wb') as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "with open('dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset, f)"
      ],
      "metadata": {
        "id": "O4mM-VmP4V-K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Cargar los datos\n",
        "with open('data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "with open('dataset.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "# Consulta del usuario\n",
        "query = \"¿Cuándo finalizó la Segunda Guerra Mundial?\"\n",
        "\n",
        "# **TF-IDF**\n",
        "# Cargo vectorizador y vectores\n",
        "with open('vectorizer.pkl', 'rb') as f:\n",
        "    vectorizer = pickle.load(f)\n",
        "start_time_tfidf = time.time()\n",
        "with open('vector_matrix.pkl', 'rb') as f:\n",
        "    vector_matrix = pickle.load(f)\n",
        "query_vec = vectorizer.transform([query])\n",
        "tfidf_similarities = cosine_similarity(query_vec, vector_matrix).flatten()\n",
        "end_time_tfidf = time.time()\n",
        "\n",
        "# Ordenar resultados TF-IDF\n",
        "ranking_tfidf = tfidf_similarities.argsort()[::-1]\n",
        "top_tfidf = [(data[idx], tfidf_similarities[idx], dataset['title'][idx]) for idx in ranking_tfidf[:5]]\n",
        "\n",
        "# **Embeddings**\n",
        "#cargo modelo y embeddings\n",
        "model = SentenceTransformer('model')\n",
        "start_time_embeddings = time.time()\n",
        "with open('data_embeddings.pkl', 'rb') as f:\n",
        "    data_embeddings = pickle.load(f)\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "embedding_similarities = util.pytorch_cos_sim(query_embedding, data_embeddings).squeeze().cpu().numpy()\n",
        "end_time_embeddings = time.time()\n",
        "\n",
        "# Ordenar resultados Embeddings\n",
        "ranking_embeddings = embedding_similarities.argsort()[::-1]\n",
        "top_embeddings = [(data[idx], embedding_similarities[idx],dataset['title'][idx]) for idx in ranking_embeddings[:5]]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"=== Resultados TF-IDF ===\")\n",
        "print(f\"Tiempo de cálculo: {end_time_tfidf - start_time_tfidf:.4f} segundos\")\n",
        "for idx, (doc, sim, tit) in enumerate(top_tfidf):\n",
        "    print(f\"\\nDocumento {idx+1}:\")\n",
        "    print(f\"Similitud: {sim:.4f}\\n{tit}\\n{doc[:300]}\")\n",
        "\n",
        "print(\"\\n=== Resultados Embeddings ===\")\n",
        "print(f\"Tiempo de cálculo: {end_time_embeddings - start_time_embeddings:.4f} segundos\")\n",
        "for idx, (doc, sim,tit) in enumerate(top_embeddings):\n",
        "    print(f\"\\nDocumento {idx+1}:\")\n",
        "    print(f\"Similitud: {sim:.4f}\\n{tit}\\n{doc[:300]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiZW1hAB2V1K",
        "outputId": "1c475847-971e-4bf3-82e7-706968ce5e83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Resultados TF-IDF ===\n",
            "Tiempo de cálculo: 1.9000 segundos\n",
            "\n",
            "Documento 1:\n",
            "Similitud: 0.2366\n",
            "Guerra mundial\n",
            "Guerra mundial es un término utilizado para referirse a una batalla que puede durar días, semanas, meses o hasta años y que puede involucrar directamente a varias naciones de distintos continentes.\n",
            "\n",
            "Discrepancias en el término \n",
            "Pese a ser aceptadas las varias guerras mundiales, publicaciones como lo\n",
            "\n",
            "Documento 2:\n",
            "Similitud: 0.2112\n",
            "Guerra\n",
            "La guerra, estrictamente hablando, es aquel conflicto social en el que dos o más grupos humanos relativamente masivos —principalmente tribus, sociedades o naciones— se enfrentan de manera violenta, generalmente mediante el uso de armas de toda índole, a menudo con resultado de muerte —individual o c\n",
            "\n",
            "Documento 3:\n",
            "Similitud: 0.1803\n",
            "Conferencia de París (1945)\n",
            "La conferencia de París de 1945 (9 de noviembre al 21 de diciembre), fue una reunión celebrada por los representantes de los Estados aliados para decidir las reparaciones de guerra a imponer a Alemania tras su derrota en la II Guerra Mundial.\n",
            "\n",
            "Véase también \n",
            " Conferencia de París (1919) - Reunión co\n",
            "\n",
            "Documento 4:\n",
            "Similitud: 0.1586\n",
            "Victoria pírrica\n",
            "Una victoria pírrica es aquella que se consigue con muchas pérdidas en el bando aparentemente o tácticamente vencedor, de modo que incluso tal victoria puede terminar siendo desfavorable para dicho bando.\n",
            "\n",
            "El nombre proviene de Pirro, rey de Epiro, quien logró una victoria sobre los romanos con el c\n",
            "\n",
            "Documento 5:\n",
            "Similitud: 0.1506\n",
            "Guerras del golfo Pérsico\n",
            "Las guerras del golfo Pérsico fueron una serie de conflictos militares armados de los siglos  y , entre países del hemisferio occidental y sus aliados e Irak:\n",
            "\n",
            " La guerra Irán-Irak (1980-1988). Fue una guerra entre Irán e Irak como resultado de la invasión del segundo, bajo el gobierno de Saddam, qu\n",
            "\n",
            "=== Resultados Embeddings ===\n",
            "Tiempo de cálculo: 0.1901 segundos\n",
            "\n",
            "Documento 1:\n",
            "Similitud: 0.7627\n",
            "1945\n",
            "1945 () fue un año común comenzado en lunes según el calendario gregoriano.\n",
            "\n",
            "Este año marcó el fin  de la Segunda Guerra Mundial, tras la derrota de las Potencias del Eje (la Italia Fascista, la Alemania Nazi  y el Japón Imperial respectivamente); las fuerzas aliadas (particularmente Estados Unidos \n",
            "\n",
            "Documento 2:\n",
            "Similitud: 0.7300\n",
            "1918\n",
            "1918 () fue un año común comenzado en martes según el calendario gregoriano. \n",
            "\n",
            "Este año marcó el fin de la Gran Guerra (Primera guerra mundial), conflicto que resultó en la muerte de entre 15 y 22 millones de personas (1 % de la población total en ese momento). Las consecuencias de la guerra continu\n",
            "\n",
            "Documento 3:\n",
            "Similitud: 0.6928\n",
            "Segunda Guerra Mundial\n",
            "La Segunda Guerra Mundial (también escrito II Guerra Mundial) fue un conflicto militar global que se desarrolló entre 1939 y 1945. En ella se vieron implicadas la mayor parte de las naciones del mundo —incluidas todas las grandes potencias, así como prácticamente todas las naciones europeas— agrupad\n",
            "\n",
            "Documento 4:\n",
            "Similitud: 0.6508\n",
            "1943\n",
            "1943 () fue un año común comenzado en viernes del calendario gregoriano.\n",
            "\n",
            "Acontecimientos\n",
            "\n",
            "Enero \n",
            " 1 de enero: en el marco de la Segunda Guerra Mundial, finaliza la larga batalla de Guadalcanal, con la victoria de los estadounidenses sobre los japoneses.\n",
            " 11 de enero: El Reino Unido y Estados Unidos\n",
            "\n",
            "Documento 5:\n",
            "Similitud: 0.6290\n",
            "1914\n",
            "1914 () fue un año común comenzado en jueves según el calendario gregoriano.\n",
            "\n",
            "En este año inició la Primera Guerra Mundial, el segundo conflicto más sangriento y destructivo de la historia humana hasta aquel momento (siendo solo superado por las Guerras Ming-Qing de 1618–1644 en China). La llamada \"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlqHsp7IaTrXKEEmC7uqTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}